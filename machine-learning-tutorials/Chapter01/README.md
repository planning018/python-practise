第一章 监督学习

知识点：

### 数据预处理技术

1. 均值移除 Mean removal

   通常我们会把每个特征的平均值移除，以保证特征均值为 0（即标准化处理）。这样做可以消除特征彼此间的偏差（bias）。

2. 范围缩放 Scaling

   数据点中每个特征的数值范围可能变化很大，因此，有时将特征的数值范围缩放到合理的大小是非常重要的。

3. 归一化 Normalization

   数据归一化用于需要对特征向量的值进行调整时，以保证每个特征向量的值都缩放到相同的数值范围。

4. 二值化 Binarization

   二值化用于将数值特征向量转换为布尔类型向量。

5. 独热编码

   可以把独热编码看作是一种收紧特征向量的工具，他把特征向量的每个特征与特征的非重复总数相对应，通过 one-of-k 的形式对每个值进行编码。

### 标记编码方法

标记编码就是要把单词标记转换成数值形式，让算法懂得如何操作标记。

使用 sklearn 的 `preprocessing.LabelEncoder()`

### 线性回归器

**回归** 是估计输入数据与连续值输出数据之间关系的过程。数据通常是实数形式的，我们的目标是估计满足输入到输出映射关系的基本函数。

**线性回归** 的目标是提取输入变量和输出变量额关联线性模型，这就要求实际输出与线性方程预测的输出的残差平方和最小化，即普通最小二乘法。

### 计算回归的准确性

回归器可以用许多不同的指标进行衡量，部分指标如下：

* 平均绝对误差 mean absolute error
* 均方误差 mean squared error
* 中位数绝对误差 median absolute error
* 解释方差分 explain variance score
* R 方得分

### 创建岭回归器

线性回归的主要问题是对 异常值 敏感。为了避免这个问题，我们引入 正则化项 的参数作为阈值来消除异常值的影响，这个方法被称为 岭回归。

### 创建多项式回归器

线性回归模型有一个主要的局限性，那就是它只能把输入数据拟合成直线，而多项式回归模型通过拟合多项式方程来克服这类问题，从而提高模型的准确性。

### 实践案例：估算房屋价格

决策树是一个树状模型，每个节点都做一个决策，从而影响最终结果。叶子节点表示输出数值，分支表示根据输入特征做出的中间决策。

带 AdaBoost 算法的决策树回归器 decision tree regressor

### 实践案例：评估共享单车的需求分布

采用 随机森林回归器 random forest regressor 估计输出结果。

它基本上就是用一组由数据集的若干子集构建的决策树构成，再用决策树平均值改善整体学习效果。







